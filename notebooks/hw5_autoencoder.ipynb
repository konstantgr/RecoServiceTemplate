{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and processing data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed1372ddab9a40f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv(\"../data/interactions_processed.csv\")\n",
    "users_df = pd.read_csv(\"../data/users_processed.csv\")\n",
    "items_df = pd.read_csv(\"../data/items_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85049f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbac8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df[\"last_watch_dt\"] < \"2021-04-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe98dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78342a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interactions_count_df = interactions_df.groupby([\"user_id\", \"item_id\"]).size().groupby(\"user_id\").size()\n",
    "print(\"# users: %d\" % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[\n",
    "    [\"user_id\"]\n",
    "]\n",
    "print(\"# users with at least 5 interactions: %d\" % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd0d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of interactions: %d\" % len(interactions_df))\n",
    "interactions_from_selected_users_df = interactions_df.merge(\n",
    "    users_with_enough_interactions_df, how=\"right\", left_on=\"user_id\", right_on=\"user_id\"\n",
    ")\n",
    "print(\"# of interactions from users with at least 5 interactions: %d\" % len(interactions_from_selected_users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df43577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1 + x, 2)\n",
    "\n",
    "\n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df.groupby([\"user_id\", \"item_id\"])[\"watched_pct\"]\n",
    "    .sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index()\n",
    ")\n",
    "print(\"# of unique user/item interactions: %d\" % len(interactions_full_df))\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_df, interactions_test_df = train_test_split(\n",
    "    interactions_full_df, stratify=interactions_full_df[\"user_id\"], test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "print(\"# interactions on Train set: %d\" % len(interactions_train_df))\n",
    "print(\"# interactions on Test set: %d\" % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing by personId to speed up the searches during evaluation\n",
    "interactions_full_indexed_df = interactions_full_df.set_index(\"user_id\")\n",
    "interactions_train_indexed_df = interactions_train_df.set_index(\"user_id\")\n",
    "interactions_test_indexed_df = interactions_test_df.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the movie information.\n",
    "    interacted_items = interactions_df.loc[person_id][\"item_id\"]\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03042d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, interactions_full_indexed_df)\n",
    "        all_items = set(interactions_full_indexed_df[\"item_id\"])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        # Getting the items in test set\n",
    "        interacted_values_testset = interactions_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset[\"item_id\"]) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset[\"item_id\"])\n",
    "        else:\n",
    "            person_interacted_items_testset = {int(interacted_values_testset[\"item_id\"])}\n",
    "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
    "\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(\n",
    "            person_id, items_to_ignore=get_items_interacted(person_id, interactions_train_indexed_df), topn=10000000000\n",
    "        )\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            # Getting a random sample (100) items the user has not interacted\n",
    "            # (to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(\n",
    "                person_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, seed=item_id % (2**32)\n",
    "            )\n",
    "\n",
    "            # Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df[\"item_id\"].isin(items_to_filter_recs)]\n",
    "            valid_recs = valid_recs_df[\"item_id\"].values\n",
    "            # Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items,\n",
    "        # when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {\n",
    "            \"hits@5_count\": hits_at_5_count,\n",
    "            \"hits@10_count\": hits_at_10_count,\n",
    "            \"interacted_count\": interacted_items_count_testset,\n",
    "            \"recall@5\": recall_at_5,\n",
    "            \"recall@10\": recall_at_10,\n",
    "        }\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        # print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(tqdm(list(interactions_test_indexed_df.index.unique().values))):\n",
    "            # if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)\n",
    "            person_metrics[\"user_id\"] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print(\"%d users processed\" % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics).sort_values(\"interacted_count\", ascending=False)\n",
    "\n",
    "        global_recall_at_5 = detailed_results_df[\"hits@5_count\"].sum() / float(\n",
    "            detailed_results_df[\"interacted_count\"].sum()\n",
    "        )\n",
    "        global_recall_at_10 = detailed_results_df[\"hits@10_count\"].sum() / float(\n",
    "            detailed_results_df[\"interacted_count\"].sum()\n",
    "        )\n",
    "\n",
    "        global_metrics = {\n",
    "            \"modelName\": model.get_model_name(),\n",
    "            \"recall@5\": global_recall_at_5,\n",
    "            \"recall@10\": global_recall_at_10,\n",
    "        }\n",
    "        return global_metrics, detailed_results_df\n",
    "\n",
    "\n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training pipeline "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2709c3a318f8f34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 42  # random seed for reproducibility\n",
    "LR = 1e-3  # learning rate, controls the speed of the training\n",
    "WEIGHT_DECAY = 0.01  # lambda for L2 reg. ()\n",
    "NUM_EPOCHS = 200  # num training epochs (how many times each instance will be processed)\n",
    "GAMMA = 0.9995  # learning rate scheduler parameter\n",
    "BATCH_SIZE = 3000  # training batch size\n",
    "EVAL_BATCH_SIZE = 3000  # evaluation batch size.\n",
    "DEVICE = \"cuda\"  #'cuda' # device to make the calculations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f52ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = interactions_train_df.append(interactions_test_indexed_df.reset_index())\n",
    "total_df[\"user_id\"], users_keys = total_df.user_id.factorize()\n",
    "total_df[\"item_id\"], items_keys = total_df.item_id.factorize()\n",
    "\n",
    "train_encoded = total_df.iloc[: len(interactions_train_df)].values\n",
    "test_encoded = total_df.iloc[len(interactions_train_df) :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e538cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [int(total_df[\"user_id\"].max() + 1), int(total_df[\"item_id\"].max() + 1)]\n",
    "X_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape).toarray()\n",
    "X_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
    "# for a given idx. This class must also have a length atribute\n",
    "class UserOrientedDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        super().__init__()  # to initialize the parent class\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self):  # We use __func__ for implementing in-built python functions\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
    "train_dl = DataLoader(UserOrientedDataset(X_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dl = DataLoader(UserOrientedDataset(X_test), batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dls = {\"train\": train_dl, \"test\": test_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27054192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 500)\n",
    "        self.linear2 = nn.Linear(500, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.tanh(self.linear1(x))\n",
    "        out = self.linear2(out)\n",
    "        return F.softmax(out, dim=1)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_and_out_features=8287):\n",
    "        super().__init__()\n",
    "        self.in_and_out_features = in_and_out_features\n",
    "        self.hidden_size = 500\n",
    "        self.attention = Attention(self.hidden_size)\n",
    "\n",
    "        self.sequential = nn.Sequential(  # NN architecture, where the modules modify the data sequentially\n",
    "            nn.Linear(in_and_out_features, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            self.attention,\n",
    "            nn.BatchNorm1d(self.hidden_size),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),  # additional hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.hidden_size),  # BatchNorm1d for the additional hidden layer\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),  # additional hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Dropout for the additional hidden layer\n",
    "            nn.Linear(self.hidden_size, in_and_out_features),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # In the forward function, you define how your model runs, from input to output\n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2c95f9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:10:53.533380600Z",
     "start_time": "2023-12-13T01:10:53.399404400Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)  # Fix random seed to have reproducible weights of model layers\n",
    "\n",
    "model = Model()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Initialize GD method, which will update the weights of the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "\n",
    "\n",
    "def rmse_for_sparse(x_pred, x_true):\n",
    "    mask = x_true > 0\n",
    "    sq_diff = (x_pred * mask - x_true) ** 2\n",
    "    mse = sq_diff.sum() / mask.sum()\n",
    "    return mse ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "# Train loop\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in [\"train\", \"test\"]:\n",
    "        with torch.set_grad_enabled(stage == \"train\"):  # Whether to start building a graph for a backward pass\n",
    "            if stage == \"train\":\n",
    "                model.train()  # Enable some \"special\" layers (will speak about later)\n",
    "            else:\n",
    "                model.eval()  # Disable some \"special\" layers (will speak about later)\n",
    "\n",
    "            loss_at_stage = 0\n",
    "            for batch in dls[stage]:\n",
    "                batch = batch.to(DEVICE)\n",
    "                x_pred = model(batch)  # forward pass: model(x_batch) -> calls forward()\n",
    "                loss = rmse_for_sparse(x_pred, batch)  # ¡Important! y_pred is always the first arg\n",
    "                if stage == \"train\":\n",
    "                    loss.backward()  # Calculate the gradients of all the parameters wrt loss\n",
    "                    optimizer.step()  # Update the parameters\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()  # Zero the saved gradient\n",
    "                loss_at_stage += loss.item() * len(batch)\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1 / 2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "\n",
    "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_pred = model(torch.Tensor(X_test).to(DEVICE))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9bf9546"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bca32fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:29:28.305384900Z",
     "start_time": "2023-12-13T01:29:28.050942300Z"
    }
   },
   "outputs": [],
   "source": [
    "class AERecommender:\n",
    "    MODEL_NAME = \"Autoencoder\"\n",
    "\n",
    "    def __init__(self, X_preds, X_train_and_val, X_test):\n",
    "        self.X_preds = X_preds.cpu().detach().numpy()\n",
    "        self.X_train_and_val = X_train_and_val\n",
    "        self.X_test = X_test\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "\n",
    "    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n",
    "        user_preds = self.X_preds[user_id][items_to_select_idx]\n",
    "        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n",
    "        return items_idx\n",
    "\n",
    "    def recommend(self, user_id, topn=10):\n",
    "        non_interacted_items = np.argwhere(self.X_test[user_id] == 0).ravel()\n",
    "\n",
    "        if len(non_interacted_items) == 0:\n",
    "            return []\n",
    "        user_preds = self.X_preds[user_id][non_interacted_items]\n",
    "        items_idx = non_interacted_items[np.argsort(-user_preds)[:topn]]\n",
    "\n",
    "        return list(items_idx)\n",
    "\n",
    "    def evaluate(self, size=100):\n",
    "        X_total = self.X_train_and_val + self.X_test\n",
    "\n",
    "        true_5 = []\n",
    "        true_10 = []\n",
    "\n",
    "        for user_id in range(len(X_test)):\n",
    "            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n",
    "            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n",
    "            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n",
    "\n",
    "            for non_zero_idx in non_zero:\n",
    "                random_non_interacted_100_items = np.random.choice(select_from, size=20, replace=False)\n",
    "                preds = self.recommend_items(user_id, np.append(random_non_interacted_100_items, non_zero_idx), topn=10)\n",
    "                true_5.append(non_zero_idx in preds[:5])\n",
    "                true_10.append(non_zero_idx in preds)\n",
    "\n",
    "        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n",
    "\n",
    "\n",
    "ae_recommender_model = AERecommender(X_pred, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d846334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:29:34.119814600Z",
     "start_time": "2023-12-13T01:29:28.863972500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall@5': 0.6073607634543179, 'recall@10': 0.8087453066332916}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_global_metrics = ae_recommender_model.evaluate()\n",
    "ae_global_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3060c0037afbcdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:29:43.595245900Z",
     "start_time": "2023-12-13T01:29:43.580224500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7347, 6278, 3463, 3270, 3310, 7430, 2669, 3955, 4539, 3821]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_recommender_model.recommend(user_id=1, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5483120393dd2b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T01:31:57.840537Z",
     "start_time": "2023-12-13T01:31:51.250354100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recos = {\n",
    "    user_id: ae_recommender_model.recommend(i, 10)\n",
    "    for i, user_id in enumerate(interactions_full_indexed_df.index.unique())\n",
    "}\n",
    "with open(\"../model_weights/custom-ae-attention-recommendations\", \"w\") as f:\n",
    "    json.dump(recos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0762e13f80b7c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
